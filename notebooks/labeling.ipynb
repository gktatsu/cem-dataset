{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling\n",
    "\n",
    "This notebook is for creating a set of labeled images to train a classifier that can identify \"good\" and \"bad\" quality images. It uses Jupyter widgets as a basic labeling interface. The labels created within this notebook are needed before running either the classify_rf.py or classify_nn.py scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "\n",
    "#this is the module with the labeling widgets\n",
    "from corrector import Dataset, PredictionsCorrector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = './'\n",
    "impaths = da.from_npy_stack(os.path.join(savedir, 'deduplicated.npz'))\n",
    "print(f'{len(impaths)} image paths in array')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we're creating labels for all the images, not just the ones that we want to label. If the number of desired labeled images is know ahead of time, set the num_images parameter. For example, for 1000 labeled images, num_images=1000. When this parameter is set the PredictionsCorrector class will stop loading new images once num_images have been loaded. Otherwise, PredictionsCorrector will continue to load images until all the images in impaths have been labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it's possible to resume from a previously created label array by setting\n",
    "#resume_labels to the path of the label array\n",
    "resume_labels = None #os.path.join(save_dir, 'patch_quality_labels.npy')\n",
    "\n",
    "if resume_labels is not None:\n",
    "    labels = np.load(resume_labels)\n",
    "    assert(len(labels) == len(impaths)), \\\n",
    "    \"Number of labels is in resumed label array does not match the number of images!\"\n",
    "else:\n",
    "    #if we're not resuming, then we'll start with all\n",
    "    #labels as \"none\"\n",
    "    labels = np.array(['none'] * len(impaths))\n",
    "    \n",
    "#make a the dataset class\n",
    "#setting the eval_label to \"none\" ensures that only unlabeled images\n",
    "#will be presented; this is especially important if we're resuming from a \n",
    "#label file that has some images marked as \"good\" or \"bad\"\n",
    "dataset = Dataset(impaths, labels=labels, num_images=None, eval_label='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time the submit button is pressed the labels for the dataset are updated. This means that it is possible to extract and save all labels before the PredictionsCorrector class has loaded all the images. For example, if the dataset contains 5000 images and the batch_size for the PredictionsCorrector is 50, it is possible to run the next two cells (which print info and save the labels) after clicking submit on the first 50 images. It's recommended that saving be done often so that labels are not lost if the notebook crashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#manually label images by changing default \"none\" to either \"good\" or \"bad\"\n",
    "#in the dropdown that appears under the image\n",
    "classes = ['good', 'bad', 'none']\n",
    "pc = PredictionsCorrector(dataset, classes, batch_size=50, rows=5) #50 images per batch in 5 rows implies 10 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bad_labels = len(np.where(np.array(pc.corrected_labels()) == 'bad')[0])\n",
    "num_good_labels = len(np.where(np.array(pc.corrected_labels()) == 'good')[0])\n",
    "num_unlabeled = len(impaths) - num_bad_labels - num_good_labels\n",
    "print(f'Images with label \"bad\": {num_bad_labels}, \"good\": {num_good_labels}, \"none\": {num_unlabeled}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the results\n",
    "#note that the saved array contains strings of either \"good\", \"bad\", or \"none\"\n",
    "np.save(os.path.join(savedir, 'patch_quality_labels.npy'), np.array(pc.corrected_labels()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
